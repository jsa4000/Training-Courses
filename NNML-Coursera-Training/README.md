Welcome to the course!

There are 16 modules ("lectures") and each module will be divided into about five short videos. In each module there will be a quiz that counts towards your final grade.

The modules are broken down into the following:

Lecture 1: Introduction
Lecture 2: The Perceptron learning procedure
Lecture 3: The backpropagation learning procedure
Lecture 4: Learning feature vectors for words
Lecture 5: Object recognition with neural nets
Lecture 6: Optimization: How to make the learning go faster
Lecture 7: Recurrent neural networks
Lecture 8: More recurrent neural networks
Lecture 9: Ways to make neural networks generalize better
Lecture 10: Combining multiple neural networks to improve generalization
Lecture 11: Hopfield nets and Boltzmann machines
Lecture 12: Restricted Boltzmann machines (RBMs)
Lecture 13: Stacking RBMs to make Deep Belief Nets
Lecture 14: Deep neural nets with generative pre-training
Lecture 15: Modeling hierarchical structure with neural nets
Lecture 16: Recent applications of deep neural nets (optional videos)

The two module quizzes

Each module, there will be two quizzes (one per lecture) that do count towards your final grade.

The programming assignments

You will need to answer questions about the results produced by the programs and your answers will count towards your final grade.

The first programming assignment will be very simple. It is mainly intended to get you to download Octave and get used to using it (see the Octave installation link). We regret that we do not have the resources to support other languages, but if you have Matlab it should be simple to adapt the Octave code we provide. You will not need to submit any code.

The final test

The final test will be 25% of the final grade, the programming assignments will be 30% and the weekly quizzes 45%.

Please remember that this course contains the same content presented on Coursera beginning in 2013. It is not a continuation or update of that original course